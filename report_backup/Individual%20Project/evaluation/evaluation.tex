\chapter{Evaluation} \label{Evaluation}
%We will be using \textit{python} version \textit{3.7.2} to develop the LSTM %pruning algorithm and a simulator to test its performance. When developing the %solution we are going to use the \textit{Keras} framework from %\textit{tensorflow}.
%
%A simulator will be developed using the \textit{pygame} library and will have a %graphical user interface\footnote{We will be using Model-View-Controller (MVC) %pattern} as well as a lightweight testing mode (so that we will have exclusive %access to resources).
%
%We will also have to generate the training data for the LSTM by converting %images generated by simultaneous localization and mapping (SLAM) devices to %simulator environments.
%
%When testing, the following aspects will be taken into account:
%\begin{itemize}
%    \item Total distance travelled
%    \item Success rate of finding a path
%    \item Total time taken in seconds
%    \item Total search space used
%    \item Environment statistics such as obstacle occupancy percentage
%    \item Machine Learning specific metrics such as training time, accuracy, %precision, F1 Score, loss
%    \item Data set metrics such as average environment statistics, mean/median %shortest distance.
%\end{itemize}

%\begin{table}[h]
%\begin{tabular}{@{}|l|l|@{}}
%\toprule
%\multicolumn{2}{|c|}{Timetable}                                                 %                      \\ \midrule
%\multicolumn{1}{|c|}{Deadline} & Task                                           %                      \\ \midrule
%26 April                       & Develop basic simulator                        %                      \\ \midrule
%03 May                         & Implement eligible algorithms                  %                      \\ \midrule
%10 May                         & Add graphical extensions of the simulator      %                      \\ \midrule
%17 May                         & Generate training data                         %                      \\ \midrule
%24 May                         & Implement LSTM architecture and solution       %                      \\ \midrule
%31 May                         & Create testing platform for proposed solution %and classic algorithms \\ \midrule
%7 June                         & Finish evaluation                              %                      \\ \midrule
%14 June                        & Final changes                                  %                      \\ \bottomrule
%\end{tabular}
%\end{table}

\section{Methodology}

In this chapter, we are going to present the empirical evaluation results. We will first inspect the synthetic generated training datasets, analyse the training procedure for the ML algorithms (Online LSTM Planner and CAE Online LSTM Planner), and lastly, we will run some experiments using the \textbf{Analyser} simple and complex evaluation procedures in order to review the performance of the proposed solution. We will analyse a variety of combinations of algorithms and training datasets described in Table \ref{tab: evalalgorithms}. 

\begin{table}[h!] 
\footnotesize 
\centerfloat
\begin{tabular}{|cc|M{4.6cm}|c|}
\hline
    \multicolumn{2}{|c|}{\textbf{Nr.}} & \textbf{Planner} & \textbf{Training Data}\\
    \hline
    \hline
    \multicolumn{2}{|c|}{\cellcolor{lightgray!20} 0} & A* & n/a\\
    \hline
    \hline
    \multicolumn{2}{|c|}{\cellcolor{red!40} 1} & Online LSTM (\cite{nicola2018lstm}) & \texttt{uniform\_random\_fill\_10000}\\
    \hline
    \multicolumn{2}{|c|}{\cellcolor{red!20} 2} & Online LSTM & \texttt{block\_map\_10000}\\
    \hline
    \multicolumn{2}{|c|}{\cellcolor{red!20} 3} & Online LSTM & \texttt{house\_10000}\\
    \hline
    \multicolumn{2}{|c|}{\cellcolor{red!20} 4} & Online LSTM & \texttt{uniform\_random\_fill\_10000\_block\_map\_10000}\\
    \hline
    \multicolumn{2}{|c|}{\cellcolor{red!20} 5} & Online LSTM & \texttt{uniform\_random\_fill\_10000\_block\_map\_10000\_house\_10000}\\
    \hline
    \hline
    \multicolumn{2}{|c|}{\cellcolor{blue!20} 6} & CAE Online LSTM & \texttt{uniform\_random\_fill\_10000}\\
    \hline
    \multicolumn{2}{|c|}{\cellcolor{blue!40} 7} & CAE Online LSTM (\cite{inoue2019robot}) & \texttt{block\_map\_10000}\\
    \hline
    \multicolumn{2}{|c|}{\cellcolor{blue!20} 8} & CAE Online LSTM & \texttt{house\_10000}\\
    \hline
    \multicolumn{2}{|c|}{\cellcolor{blue!20} 9} & CAE Online LSTM & \texttt{uniform\_random\_fill\_10000\_block\_map\_10000}\\
    \hline
    \multicolumn{2}{|c|}{\cellcolor{blue!20} 10} & CAE Online LSTM & \texttt{uniform\_random\_fill\_10000\_block\_map\_10000\_house\_10000}\\
    \hline
    \hline
    \multicolumn{2}{|c|}{\cellcolor{orange!40} 11} & LSTM Bagging & See Table \ref{tab: eval_lstm_bagging} \\
    \hline
    \hline
    \multicolumn{1}{|M{0.15cm}}{\cellcolor{cyan!40}} & \multicolumn{1}{M{0.15cm}|}{\cellcolor{blue!40} \hspace*{-0.5cm}12} & Global Way-point LSTM GK: CAE Online LSTM & \texttt{block\_map\_10000}\\
    \hline
    \multicolumn{1}{|M{0.15cm}}{\cellcolor{cyan!40}} & \multicolumn{1}{M{0.15cm}|}{\cellcolor{red!40} \hspace*{-0.5cm}13} & Global Way-point LSTM GK: Online LSTM & \texttt{uniform\_random\_fill\_10000\_block\_map\_10000\_house\_10000}\\
    \hline
    \multicolumn{1}{|M{0.15cm}}{\cellcolor{cyan!40}} & \multicolumn{1}{M{0.15cm}|}{\cellcolor{orange!40} \hspace*{-0.5cm}14} & Global Way-point LSTM GK: LSTM Bagging (proposed solution) & See Table \ref{tab: eval_lstm_bagging} \\
    \hline
    \end{tabular}
\caption{Evaluated algorithms and their respective training dataset. All algorithms are colour-coded: A* is light-grey, Online LSTM Planner is red (solution with same training dataset as \cite{nicola2018lstm} is darker red), CAE Online LSTM Planner is blue (solution with same training dataset as \cite{inoue2019robot} is darker blue), LSTM Bagging Planner is orange, Global Way-point LSTM Planner is half cyan and half global kernel colour (e.g. Algorithm 14 has both cyan and orange colours as it uses the LSTM Bagging Planner as the GK)}
\label{tab: evalalgorithms} 
\end{table}

In the future sections we will use a shorthand notation based on the algorithm index when talking about a particular solution, and we will reduce the number of inspected algorithms based on their performance. The proposed solution (Algorithm \hyperref[tab: evalalgorithms]{14}) has local kernel A* (Algorithm \hyperref[tab: evalalgorithms]{0}) and global kernel LSTM Bagging Planner (Algorithm \hyperref[tab: evalalgorithms]{11}). The kernel configuration for Algorithms \hyperref[tab: evalalgorithms]{11} and \hyperref[tab: evalalgorithms]{14} is described in Table \ref{tab: eval_lstm_bagging}. A* (Algorithm \hyperref[tab: evalalgorithms]{0}) is used as ground truth when training the ML models, and represents the comparison standard against all other algorithms. Algorithm \hyperref[tab: evalalgorithms]{1} has the same training dataset as \cite{nicola2018lstm}, and Algorithm \hyperref[tab: evalalgorithms]{7} has same training dataset as \cite{inoue2019robot}. Algorithms \hyperref[tab: evalalgorithms]{12} and \hyperref[tab: evalalgorithms]{13} use Algorithms \hyperref[tab: evalalgorithms]{7} and \hyperref[tab: evalalgorithms]{5} (Algorithm \hyperref[tab: evalalgorithms]{5} was chosen over \hyperref[tab: evalalgorithms]{1} as it has better results) respectively as their global kernel. The reason behind evaluating Algorithms \hyperref[tab: evalalgorithms]{12} and \hyperref[tab: evalalgorithms]{13} is that we would like to inspect if the results of using the Global Way-point LSTM Planner with global kernel Online LSTM Planner and CAE Online LSTM Planner respectively achieve better results than the proposed solution (which uses the LSTM Bagging Planner as the global kernel).

%Algorithm \hyperref[tab: evalalgorithms]{14} is the proposed solution: Global Way-point LSTM Planner with A* local kernel and LSTM Bagging Planner global kernel. The kernel configuration for Algorithms \hyperref[tab: evalalgorithms]{11} and \hyperref[tab: evalalgorithms]{14} is described in Table \ref{tab: eval_lstm_bagging}. Algorithm \hyperref[tab: evalalgorithms]{0} (A*) is used as ground truth when training the ML models and we will compare the performance of other algorithms against it. Algorithm \hyperref[tab: evalalgorithms]{1} is a close representation of \cite{nicola2018lstm} and Algorithm \hyperref[tab: evalalgorithms]{7} is a close representation of \cite{inoue2019robot}. Algorithms \hyperref[tab: evalalgorithms]{12} and \hyperref[tab: evalalgorithms]{13} use Algorithms \hyperref[tab: evalalgorithms]{7} and \hyperref[tab: evalalgorithms]{5} respectively as their global kernel. The reason behind evaluating \hyperref[tab: evalalgorithms]{12} and \hyperref[tab: evalalgorithms]{13} is that we would like to inspect if the results of combining the Global Way-point LSTM Planner with the paper solutions (\cite{nicola2018lstm} and \cite{inoue2019robot}) achive better results.

\begin{table}[h!]
    \centerfloat
    \begin{tabular}{|M{2cm}|c|c|}
         \hline
         \textbf{Kernel} & \textbf{Training Data} & \textbf{Algorithm}\\
         \hline
         \hline
         CAE Online LSTM & \texttt{block\_map\_10000} & \cellcolor{blue!40} \hyperref[tab: evalalgorithms]{7} \\
         \hline
         CAE Online LSTM & \texttt{uniform\_random\_fill\_10000} & \cellcolor{blue!20} \hyperref[tab: evalalgorithms]{6} \\
         \hline
         CAE Online LSTM & \texttt{house\_10000} & \cellcolor{blue!20} \hyperref[tab: evalalgorithms]{8} \\
         \hline
         CAE Online LSTM & \texttt{uniform\_random\_fill\_10000\_block\_map\_10000\_house\_10000} & \cellcolor{blue!20} \hyperref[tab: evalalgorithms]{9} \\
         \hline
         CAE Online LSTM & \texttt{uniform\_random\_fill\_10000\_block\_map\_10000} & \cellcolor{blue!20} \hyperref[tab: evalalgorithms]{10} \\
         \hline
         \hline
         Online LSTM & \texttt{uniform\_random\_fill\_10000} & \cellcolor{red!40} \hyperref[tab: evalalgorithms]{1} \\
         \hline
         Online LSTM & \texttt{block\_map\_10000} & \cellcolor{red!20} \hyperref[tab: evalalgorithms]{2} \\
         \hline
         Online LSTM & \texttt{house\_10000} & \cellcolor{red!20} \hyperref[tab: evalalgorithms]{3} \\
         \hline
         Online LSTM & \texttt{uniform\_random\_fill\_10000\_block\_map\_10000} & \cellcolor{red!20} \hyperref[tab: evalalgorithms]{4} \\
         \hline
         Online LSTM & \texttt{uniform\_random\_fill\_10000\_block\_map\_10000\_house\_10000} & \cellcolor{red!20} \hyperref[tab: evalalgorithms]{5} \\ 
         \hline
    \end{tabular}
    \caption{LSTM Bagging Planner (Algorithms  \hyperref[tab: evalalgorithms]{11} and \hyperref[tab: evalalgorithms]{14}) kernel configuration in priority order}
    \label{tab: eval_lstm_bagging}
\end{table}

\section{Synthetic Training Datasets Analysis}

We have three types of generated synthetic maps: uniform random fill map, block map and house map. The map generation process is described in the Section \ref {sec: generator} (\hyperref[sec: generator]{Generator}). The generated maps are described in Figure \ref{fig: eval_generated maps}. The analysis of the training datasets can be found in Table \ref{tab: eval_maps}.

%\begin{itemize}
%    \item 10000 uniform\_random\_fill (64x64 dimension, [0.1, 0.3] obstacle fill rate range, 430 MB disk size)
%    \item 10000 block\_map (64x64 dimension, [0.1, 0.3] obstacle fill rate range, [1, 6] number of obstacles range, 400 MB disk %size)
%    \item 10000 house (64x64 dimension, [8, 15] minimum room size range, [35, 45] maximum room size range, 230 MB disk size)
%\end{itemize}

\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.30\linewidth}
    \includegraphics[width=\linewidth]{images/screenshot_52.png}
     \caption{Uniform random fill map ([0.1, 0.3] obstacle fill rate range, 430 MB disk size)\newline}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.30\linewidth}
    \includegraphics[width=\linewidth]{images/screenshot_54.png}
     \caption{Block map ([0.1, 0.3] obstacle fill rate range, [1, 6] number of obstacles range, 400 MB disk size)}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.30\linewidth}
    \includegraphics[width=\linewidth]{images/screenshot_53.png}
     \caption{House map ([8, 15] minimum room size range, [35, 45] maximum room size range, 230 MB disk size)}
  \end{subfigure}
  \caption{Synthetic generated maps (10000 samples of $64\times64$ dimension for each map)}
  \label{fig: eval_generated maps}
\end{figure}

\pagebreak

\begin{table}[h!] 
\small
\centerfloat
    \begin{tabular}{|c|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1.5cm}|M{1cm}|}
    \hline
    \textbf{Training Dataset Name} & \textbf{Path Available} & \textbf{Obstacles} & \textbf{Original Distance} & \textbf{Optimal Travel Distance} & \textbf{Disk Size} \\
    \hline
    \texttt{uniform\_random\_fill\_10000} & 99.97\% & 19.95\% & 33.55 & 36.07 & 2GB \\
    \hline
    \texttt{block\_map\_10000} & 99.99\% & 18.68\% & 34.35 & 38.92 & 2GB \\
    \hline
    \texttt{house\_10000} & 96.88\% & 8.25\% & 33.54 & 41.06 & 2GB \\
    \hline
    \end{tabular}
\caption{Synthetic training datasets evaluation (all results are averaged)}
\label{tab: eval_maps}
\end{table}

\section{Training Analysis}
The training pipeline was run in the Google Colab environment (See Table \ref{tab: colab specs}).

\begin{table}[h!]
    \centerfloat
    \begin{tabular}{|c|M{13cm}|}
         \hline
         \textbf{Name} & \textbf{Value} \\
         \hline
         GPU & GPU 0: NVIDIA Tesla T4 (2496 CUDA cores, Compute 3.7,  12GB(11.439GB Usable) GDDR5 VRAM) \\
         \hline
         CPU & Intel(R) Xeon(R) CPU @ 2.30GHz (No Turbo Boost, 1 Core, 2 Threads, 45 MB Cache) \\
         \hline
         RAM & \textasciitilde12.6 GB \\
         \hline
         Disk & \textasciitilde320 GB \\
         \hline
    \end{tabular}
    \caption{Google Colab machine specifications \cite{colab_specs}}
    \label{tab: colab specs}
\end{table}

All training data was synthetically generated and we have a total of 30000 maps. It would have been better if we would have used a SLAM image dataset and convert it to internal maps as we would have had real-world data (e.g. the SUNCG dataset \cite{song2017semantic}). However, due to time restrictions, we had to generate the training data as it was faster. Moreover, we have control over the type of map and map parameters (obstacle fill rate, number of obstacles, min-max room size).

The training process is different from \cite{nicola2018lstm} and \cite{inoue2019robot}. In \cite{nicola2018lstm}, the authors use four types of maps: mazes with corridor having 4 steps width, mazes with corridor having 2 steps width, random filled for 25\% map size and random filled for 40\% of the map size. The number of maps is 5 for the training set and 3 for the validation set. Paths are generated using A* and are randomly selected from the available maps. The final training process results are: 0.3208 loss, 89.97\% train accuracy and 88.60\% validation accuracy. In \cite{inoue2019robot}, the authors state that a large amount of environmental images that contain randomly placed block obstacles (similar to our block map generated maps) has been used to train the CAE section, and 10 hard-codded maps with 10000 random paths for each map have been used to train the LSTM section. It should be noted that the paths are generated using RRT instead of A* and are modified by using a trajectory refinement method to extract high-quality paths. No training results have been provided.

Our training process uses three types of maps: uniform random fill map, block map and house map. We have a total of 30000 maps and separate datasets which use a subset of the maps based on the map type or the whole 30000 maps. We only generate a single path using A* for each map and we do not refine the trajectory. It should be noted that could have boosted the training dataset by sampling more paths from each map, but 30000 samples were enough (or a subset depending on the type of dataset). A major difference between our training procedure and the above training procedures is that we use a large number of environments for training the models and thus, we avoid over-fitting. Moreover, we can run experiments on a larger subset of maps and thus, we are more confident that our results are accurate and generalise well on different unseen environments.

\subsection{Online LSTM Planner}

The Online LSTM Planner has extra training configuration options described in Table \ref{tab: lstm_extra_config}. 

\begin{table}[h!]
    \centerfloat
    \begin{tabular}{|M{3.4cm}|c|M{2.0cm}|M{5cm}|}
         \hline
         \textbf{Key} & \textbf{Pipeline Section} & \textbf{Type} & \textbf{Description} \\
         \hline
         num\_layers & Model Loading & \texttt{int} & Number of LSTM layers\\
         \hline
         lstm\_input\_size & Model Loading & \texttt{int} & LSTM input size \\
         \hline
         lstm\_output\_size & Model Loading & \texttt{int} & LSTM output size\\
         \hline
    \end{tabular}
    \caption{Online LSTM Planner extra training configuration options}
    \label{tab: lstm_extra_config}
\end{table}

The training parameters for the Online LSTM model are given in Table \ref{tab: eval_training_online_lstm}. All Online LSTM models use the same training configuration. We are going to evaluate each model training and report the following statistics: Training Loss (last training epoch loss), Validation Loss (last validation epoch loss), Evaluation Loss (test loss), Accuracy (evaluation accuracy), Precision (evaluation precision), Recall (evaluation recall), F1 (evaluation F1) and Confusion Matrix (confusion matrix of the predicted actions; actions are: 0 (go right), 1 (go top right), 2 (go top), 3 (go top left), 4 (go left), 5 (go bottom left), 6 (go bottom) and 7 (go bottom right) (See Figure \ref{fig: confusion_matrix})) (See Table \ref{tab: gen_online_lstm_final_tr_res}). The \textit{sklearn} library \cite{sklearn_api} has been used to produce all measurements and because we are using multi-class classification (we have 8 actions), we have used macro averaging for all statistics, which is a more "severe" measurement (outliers are equally punished and not weighted).

\begin{table}[h!]
    \centerfloat
    \begin{tabular}{|c|M{11cm}|}
        \hline
        \textbf{Key} & \textbf{Value} \\
        \hline
     	data\_features & [distance\_to\_goal\_normalized, raycast\_8\_normalized, direction\_to\_goal\_normalized, agent\_goal\_angle] \\
     	\hline
    	data\_labels & [next\_position\_index] \\
    	\hline
    	data\_single\_features & [] \\
    	\hline
    	data\_single\_labels & [] \\
    	\hline
    	epochs & 100 \\
    	\hline
    	loss & \texttt{CrossEntropyLoss} \\
    	\hline
    	optimizer & \texttt{lambda model: Adam(model.parameters(), lr=0.01)} \\
    	\hline
    	validation\_ratio & 0.2 \\
    	\hline
    	test\_ratio & 0.2 \\
    	\hline
    	save\_name & \texttt{tile\_by\_tile} \\
    	\hline
    	training\_data & See Table \ref{tab: evalalgorithms} \\
    	\hline
    	batch\_size & 50 \\
    	\hline
    	num\_layers & 2 \\
    	\hline
    	lstm\_input\_size & 12 \\
    	\hline
    	lstm\_output\_size & 8 \\
    	\hline
    \end{tabular}
    \caption{Online LSTM Planner training configuration}
    \label{tab: eval_training_online_lstm}
\end{table}

\begin{table}[h!]
    \footnotesize
    \centerfloat
    \begin{tabular}{|c|M{1.5cm}|M{1.5cm}|M{1.5cm}|c|c|c|c|M{1.5cm}|}
         \hline
         \textbf{Model} & \textbf{Training Loss} & \textbf{Validation Loss} & \textbf{Evaluation Loss} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{Confusion Matrix} \\
         \hline
         \cellcolor{red!40} \hyperref[tab: evalalgorithms]{1} & 0.033805 & 0.225089 & 0.141824 & 0.96 & 0.96 & 0.96 & 0.96 & See Table \ref{tab: gen_cm_online_lstm_1} \\
         \hline
         \cellcolor{red!20} \hyperref[tab: evalalgorithms]{2} & 0.032614 & 0.105727 & 0.077589 & 0.98 & 0.97 & 0.97 & 0.97 & See Table \ref{tab: cm_online_lstm_2} \\
         \hline
         \cellcolor{red!20} \hyperref[tab: evalalgorithms]{3} & 0.110707 & 0.430041 & 0.357634 & 0.91 & 0.91 & 0.91 & 0.91 & See Table \ref{tab: cm_online_lstm_3} \\
         \hline
         \cellcolor{red!20} \hyperref[tab: evalalgorithms]{4} & 0.029944 & 0.090220 & 0.071301 & 0.97 & 0.97 & 0.97 & 0.97 & See Table \ref{tab: cm_online_lstm_4} \\
         \hline
         \cellcolor{red!20} \hyperref[tab: evalalgorithms]{5} & 0.025989 & 0.114388 & 0.115875 & 0.92 & 0.92 & 0.92 & 0.92 & See Table \ref{tab: cm_online_lstm_5} \\
         \hline
    \end{tabular}
    \caption{Online LSTM Planner final training statistics}
    \label{tab: gen_online_lstm_final_tr_res}
\end{table}

\pagebreak

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.30]{images/confusion_matrix.png}
    \caption{Confusion matrix visualisation \cite{conf_mat}}
    \label{fig: confusion_matrix}
\end{figure}

\begin{table}[h!]
\centering
\small
    \begin{tabular}{|c|c|cccccccc|} 
    \hline & \multicolumn{9}{c|}{\textbf{Predicted}} \\ 
    \hline
    \multirow{9}{*}{\rotatebox{90}{\textbf{Actual}}} & \textbf{Action} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{6} & 7  \\ 
    \cline{2-10} & \multicolumn{1}{c|}{0} & 175 &   0 &  7 &   0 &   0 &   1 &   3 &   0 \\
    \cline{2-2}  & \multicolumn{1}{c|}{1} &   4 & 207 &  2 &   0 &   0 &   0 &   0 &   0 \\
    \cline{2-2}  & \multicolumn{1}{c|}{2} &   0 &   0 & 97 &   0 &   2 &   0 &   0 &   0 \\
    \cline{2-2}  & \multicolumn{1}{c|}{3} &   0 &   0 &  0 & 202 &   1 &   0 &   0 &   0 \\
    \cline{2-2}  & \multicolumn{1}{c|}{4} &   0 &   0 &  0 &   0 & 135 &   1 &   0 &   0 \\
    \cline{2-2}  & \multicolumn{1}{c|}{5} &   0 &   0 &  1 &   0 &   0 & 227 &   5 &   1 \\
    \cline{2-2}  & \multicolumn{1}{c|}{6} &   0 &   0 &  0 &   1 &   1 &   0 & 160 &   0 \\
    \cline{2-2}  & \multicolumn{1}{c|}{7} &   7 &   0 &  1 &   0 &   0 &   3 &   5 & 164 \\
    \hline
    \end{tabular}
    \caption{Confusion matrix for Algorithm \hyperref[tab: evalalgorithms]{1}}
        \label{tab: gen_cm_online_lstm_1}
\end{table}

\begin{figure}[h!]
  \centerfloat
  \begin{subfigure}[b]{0.35\linewidth}
    \includegraphics[width=\linewidth]{images/trained_online_lstm/tile_by_tile_training_uniform_random_fill_10000_model_loss.png}
     \caption{Training/Validation Loss}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.35\linewidth}
    \includegraphics[width=\linewidth]{images/trained_online_lstm/tile_by_tile_training_uniform_random_fill_10000_model_training_stats.png}
     \caption{Training Statistics}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.35\linewidth}
    \includegraphics[width=\linewidth]{images/trained_online_lstm/tile_by_tile_training_uniform_random_fill_10000_model_validation_stats.png}
     \caption{Validation Statistics}
  \end{subfigure}
  \caption{Training statistics for Algorithm \hyperref[tab: evalalgorithms]{1}}
  \label{fig: gen_train_olnine_lstm_1}
\end{figure}

\FloatBarrier

From the training results (See Figure \ref{fig: gen_train_olnine_lstm_1}) we can notice that the models have not experienced over-fitting. All models have higher accuracy than \cite{nicola2018lstm} (which has 89.97\% training accuracy and 88.60\% validation accuracy). Best trained models are Algorithms \hyperref[tab: evalalgorithms]{2} and \hyperref[tab: evalalgorithms]{4}, but the other models are not far away. The confusion matrix (See Table \ref{tab: gen_cm_online_lstm_1}) shows that we do not have a preferred action. For the full training statistics please refer to Appendix \ref{sec: app_evaluation}.

\input{evaluation/evaluation_cae_train.tex}